% created on 2019-12-13
% @author : bmazoyer

%% Lines to compile only this capter
\documentclass[11pt, twoside, a4paper, openright]{report}
\input{../source/packages.tex}

\begin{document}
%%

\graphicspath{ {../figures/mocks/} }

\chapter{Validation des mocks}
\minitoc
\newpage
\thispagestyle{fancy}


Ce chapitre a pour vocation de présenter l'anayse menée sur les mocks, afin de valider leur construction et le choix des différents paramètres. Nous présentons d'abord le calcul des diverses fonctions de corrélations, puis l'analyse des 100 réalisations produites. Pour faire cette analyse, nous utilisons le code \texttt{picca} qui permet de calculer les champs $\delta$, les fonctions de corrélations, les matrices de distorsion, les matrices de covariance ainsi que de réaliser l'ajustement du modèle.

\section{Les estimateurs}
Nous présentons ici les estimateurs utilisés pour calculeur la fonction d'auto-corrélation du \lya{}, la fonction de corrélation croisée \lya{}-QSO, ainsi que la fonction d'auto-corrélation d'objets ponctuels tels les quasars.
Dans le cas des objets ponctuels, la seule information nécessaire au calcul de la fonction de corrélation est le catalogue fournissant pour chaque objet l'ascension droite, la déclinaison et le redshift. Pour le calcul des fonctions de corrélation impliquant le \lya{}, il est nécessaire de calculer au préalable le champ $\delta_F$ (équation~\ref{eq:deltaF}). Nous distingons deux cas : le cas où nous analysons les \emph{raw mocks} et le cas où nous analysons les \emph{cooked mock} ou les données.
Les raw mocks (les mocks bruts, non préparés) désignent les mocks avant d'avoir tourné le code \texttt{quickquasars}.
Les fonctions de corrélation sont alors calculées en utilisant directement la fraction de flux transmise $F$ donnée dans les fichiers de transmissions. Etant donné que pour chaque forêt, nous avons directement accèss à $F$, le champ $\delta_F$ est donné par
\begin{equation}
  \delta_F = \frac{F}{\overline F} - 1 \; .
\end{equation}
Les coocked mocks quant à eux désignent les mocks après avoir appliqué \texttt{quickquasars} à chaque forêt. Dans ce cas, comme pour les données, la fraction de flux transmise $F$ n'est pas accessible. Il faut alors utiliser la procédure d'ajustement du continuum décrite dans la section~\ref{subsec:calcul_delta}.
Une fois le champ $\delta_F$ calculé, nous pouvons calculer les différentes fonctions de corrélation.

\subsection{L'auto-corrélation \lya{}$\times$\lya{}}
Comme expliqué dans le chapitre d'introduction, la fonction d'auto-corrélation du champ d'absorption $F$ du \lya{} est définie comme
\begin{equation}
  \xi_{\mathrm{Ly}\alpha}(\vec r) = \langle \delta_F(\vec{r'}) \delta_F(\vec{r} + \vec{r'}) \rangle \; .
\end{equation}
Elle peut-être mise sous la forme
\begin{equation}
  \xi(\vec r) = \langle \delta_i \delta_j \rangle \; ,
\end{equation}
où $\langle .\rangle$ désigne la moyenne sur tous les pixels $i$ et $j$ qui vérifient $\vec r_{ij} = \vec r$.
Afin de calculer $\xi_{\mathrm{Ly}\alpha}$, nous créons une grille en $(\rpar{}, \rperp{})$.
% Chaque bin de cette grille fait $(\SI{4}{\perh\Mpc})^3$.
Les bins mesurent \SI{4}{\perh\Mpc} dans chaque direction.
Cette taille de bin permet à la fois de regrouper suffisamment de pixels pour avoir une bonne statistique dans chaque bin, mais aussi d'avoir suffisamment de bins pour résoudre correctement la région du pic BAO (\#prov est-ce que c'est vrai ? toujours la meme quantite d'info, donc ca ameliore pas le fit?).
Une fois cette grille construite, nous transformons les coordonnées $(\alpha, \delta, z)$ des pixels $\delta_F$ en distances (\#prov donner les transformations géométriques ?).
Puis, pour chaque bin $A$ de la grille en $(\rpar{}, \rperp{})$, nous considérons toutes les paires de pixels dont la distance de séparation se trouve dans ce bin $A$. La fonction de corrélation dans ce bin est alors donnée par
\begin{equation}
  \label{eq:xiff}
  \xi_A = \frac{
    \sum\limits_{(i,j)\in A} w_i w_j \delta_i \delta_j
  }{
    \sum\limits_{(i,j)\in A} w_i w_j
  }
  \; ,
\end{equation}
% où $w_i$ est le poids associé au pixel $i$. Les poids utilisés dans le calcul des fonctions de corrélation sont les poids définis dans l'équation~\ref{eq:weights}, corrigés par la dépendance en redshift du champ d'absorption du \lya{}. Le champ du \lya{} varie comme
% \begin{equation}
%   \delta_{\mathrm{Ly}\alpha}(z) = \delta_{\mathrm{Ly}\alpha}(0) \frac{b_{\mathrm{Ly}\alpha}(z) G(z)}{b_{\mathrm{Ly}\alpha}(0)G(0)} \; .
% \end{equation}
% Le facteur de croissance varie comme $G(z) \propto (1+z)^{-1}$, et le biais du \lya{} comme $b_{\mathrm{Ly}\alpha}(z) \propto (1+z)^{\gamma}$.
% Le champ $\delta_{\mathrm{Ly}\alpha}(z)$ est donc proportionnel à $(1+z)^{\gamma - 1}$. Le paramètre $\gamma = 2.9$ est mesuré sur le spectre de puissance à une dimension du \lya \citep{McDonald2004} (\#prov j'ai pas trouvé dans le papier à quel endroit était donnée la mesure).
% Ainsi, les poids utilisés dans l'équation~\ref{eq:xiff} sont donnés par
% \begin{equation}
%   \label{eq:weights2}
%   w_i = (1+z)^{\gamma - 1} \hat w_i \; ,
% \end{equation}
% où $\hat w_i$ sont les poids définis dans l'équation~\ref{eq:weights}.
% Le calcul de la fonction de corrélation est donc effectué à l'aide d'une double boucle sur les pixels.
où $w_i$ est le poids associé au pixel $i$. Ces poids sont définis dans l'équation~\ref{eq:weights2}. La correction de la dépendance en redshift du biais du \lya{} permet de donner plus de poids aux pixels à grand redshift, où l'amplitude de la fonction de corrélation est plus importante.
Le calcul de la fonction de corrélation est donc effectué à l'aide d'une double boucle sur les pixels.
Afin de réduire le temps de calcul, nous calculons la fonction de corrélation uniquement pour les paires de pixels pour lesquelles $\rpar{}$ et $\rperp{}$ sont inclus dans $[0 ; 200] \si{\perh\Mpc}$. La fonction de corrélation est donc calculée dans $50 \times 50 = \num{2500}$ bins.
Les paires formées par des pixels provenant de la même forêt sont exclues du calcul afin d'éviter que les erreurs sur l'ajustement du continuum biaisent la mesure de la fonction de corrélation.

L'analyse \lya{} des données complète d'eBOSS \citep{prov} utilise deux fonctions de corrélation distinctes : les fonctions de corrélation \lyalya{}$\times$\lyalya{} et \lyalya{}$\times$\lyalyb{}. La région \lyb{} ne fournit pas suffisamment de pixels pour pouvoir calculer la fonction de corrélation \lyalyb{}$\times$\lyalyb{} et y détecter le pic BAO. L'utilisation de ces deux fonctions de corrélation permet de mesurer la position du pic BAO avec une plus grande précision. Dans ce manuscrit, nous nous intéressons à la mesure de $b_{\mathrm{Ly}\alpha}$ et $\beta_{\mathrm{Ly}\alpha}$ afin de construire correctement nos mocks. Pour limiter les potentielles systématiques, nous considérons donc uniquement la fonction de corrélation \lyalya{}$\times$\lyalya{}.
Le graphique de droite de la figure~\ref{fig:pixel_number} présente les distributions pondérées en redshift des paires \lyalya{}$\times$\lyalya{} et \lyalya{}$\times$\lyalyb{}. L'analyse des données DR16 que nous présentons ici considère donc uniquement la distribution indiquée en orange.


\subsection{La corrélation croisée \lya{}$\times$QSO}
Nous donnons dans cette section l'estimateur de la fonction de corrélation croisée \lya{}$\times$QSO. De la même manière que précédemment, le calcul s'effectue dans des bins en $(\rpar{}, \rperp{})$. La fonction de corrélation dans le bin $A$ est donnée par
\begin{equation}
  \label{eq:xiqf}
  \xi_A = \frac{
    \sum\limits_{(i,j)\in A} w_i w_j \delta_i
  }{
    \sum\limits_{(i,j)\in A} w_i w_j
  }
  \; ,
\end{equation}
où l'indice $i$ court sur les pixels des forêts et $j$ sur les quasars pour lesquels la distance de séparation est comprise dans le bin $A$. Comme précédemment, les paires $ij$ où le pixel $i$ appartient à la forêt du quasar $j$ sont rejetées.
% Aussi, comme pour le \lya{}, les poids $w_j$ associés aux quasars incluent la dépendance avec le redshift du biais des quasars. Similairement à l'équation~\ref{eq:weights2}, ils sont définis comme
Les poids $w_j$ associés aux quasars, similairement au \lya{}, favorisent les quasars à plus grand redshift. Ces poids sont définis comme
\begin{equation}
  \label{eq:weights3}
  w_j = \left(\frac{1 + z_j}{1 + \num{2.25}}\right)^{\gamma_{\textsc{QSO}}} \; ,
\end{equation}
où $\gamma_{\textsc{QSO}} = \num{1.44} \pm \num{0.08}$ \citep{Bourboux2019}. Dans le calcul de la fonction de corrélation croisée \lya{}$\times$QSO, nous nous restreignons aux paires pour lesquelles $\rperp{} \in [0 ; 200] \si{\perh\Mpc}$.
Contrairement à l'auto-corrélation du \lya{}, la fonction de corrélation croisée n'est pas symétrique en $\rpar{}$. Nous la calculons donc dans les bins pour lesquels $\rpar{} \in [-200 ; 200] \si{\perh\Mpc}$. La fonction de corrélation croisée est donc calculée dans $50 \times 50 = \num{2500}$ bins.


\subsection{Le spectre de puissance à une dimension}
Comme expliqué dans le chapitre précédent, nous ajustons le spectre de puissance $P_{miss}$ appliqué à $\delta_s$ de façon à obtenir un spectre de puissance à une dimension $P^{1D}$ en accord avec les données. Nous présentons donc maintenant la mesure de ce spectre de puissance. Pour chaque forêt, nous appliquons une transformation de Fourier au champ $\delta_F$ afin d'obtenir le champ $\delta_k$. Puis, le spectre de puissance de cette forêt est obtenu comme
\begin{equation}
  P^{1D}(k) = | \delta_k^2 | \; .
\end{equation}
Nous répétons cette procédure pour toutes les forêts, puis le spectre de puissance total est obtenu comme la moyenne du spectre de puissance de chaque forêt.

En ce qui concerne les données, la mesure du spectre de puissance à une dimension est plus complexe. Un certain nombre d'effets liés à la mesure doivent être pris en compte. Le bruit, par exemple, doit être estimé afin d'être pris en compte pour ne pas fausser l'estimation du spectre de puissance. Cette analyse est détaillée dans~\citet{Chabanier2018}.

\subsection{La fonction de corrélation à une dimension}

Important / nécessaire ?


\section{Les matrices de distorsion}
L'ajustement du continuum nécessaire au calcul du champ $\delta_F$ dans les données et les coocked mocks biaise le champ mesuré. Cependant, grâce à la transformation (équation~\ref{eq:deltaF3}) décrite dans la section~\ref{subsec:projdelta}), l'effet sur la fonction de corrélation peut-être pris en compte.
% L'idée est la suivante : plutôt que d'essayer de corriger la distorsion induite par l'ajustement du continuum sur la fonction de corrélation, cette distorsion est calculée et appliquée au modèle qui est ajusté aux données (\#prov pourquoi on inverse pas la dmat?).
L'idée est la suivante : modéliser la distorsion induite par l'ajustement du continuum et par la transformation~\ref{eq:deltaF3} sur la fonction de corrélation, appliquer cette distorsion au modèle, puis ajuster le modèle ``distordu'' aux données. L'ajustement du continuum et la transformation~\ref{eq:deltaF3} induisent des corrélation le long de la ligne de visée. Au premier ordre, nous pouvons considérer que chaque $\delta_F$ d'une forêt est une combinaison linéaire de tous les $\delta_F$ de cette forêt. La fonction de corrélation distordue dans le bin $A$ peut alors être reliée à la vraie fonction de corrélation comme
\begin{equation}
  \xi_{distortion}(A) = \sum_{B} D_{AB}\xi_{vraie}(B) \; , 
\end{equation}
où $D_{AB}$ est appelée la \emph{matrice de distorsion}. Celle-ci s'exprime en fonction du projecteur $\eta_{ij}^q$ défini dans l'équation~\ref{eq:proj1}. Pour l'auto-corrélation, elle est défini comme
\begin{equation}
  \label{eq:dmat}
  D_{AB} = \frac{1}{W_A} \sum_{(i,j)\in A} w_i w_j \left( \sum_{(i',j')\in B} \eta_{ii'} \eta_{jj'} \right) \,
\end{equation}
où $W_{A} = \sum_{(i,j)\in A} w_i w_j$ est le poids du bin A. Pour la corrélation croisée, la matrice de distorsion est donnée par
\begin{equation}
  \label{eq:xdmat}
  D_{AB} = \frac{1}{W_A} \sum_{(i,j)\in A} w_i w_j \left( \sum_{(i',j')\in B} \eta_{ii'} \right) \, .
\end{equation}
Comme précédemment, les indices $i$ correspondent aux pixels des forêts, et $j$ aux quasars. A cause de la double somme, le calcul de la matrice de distorsion est très long. Afin de rendre possible l'estimation de cette dernière, le calcul est fait sur \SI{1}{\percent} des paires, tirées au hasard (\#prov Bautista 2017 montre que c'est OK avec 5\%, est-ce que y a une etude qui montre que c'est ok avec 1\% ? Dans DR14, ils utilisent 5\% je pense).
% L'étude présentée dans~\citet{bautista_measurement_2017}

La figure~\ref{prov} (\#prov faire la figure) montre l'effet de la distorsion sur l'auto-corrélation \lya{}$\times$\lya{} dans les mocks. La fonction de corrélation est présentée dans quatres gammes en $\mu$. La courbe noire indique la fonction de corrélation calculée sur les raw mocks, et la courbe bleu la fonction de ....
\#prov Refaire la figure 11 de Bautista : CF des raw mocks (stack) + CF sur les coocked mocks (stack) avec le fit sur les raw + fit * DM


La matrice de distorsion est un objet uniquement géométrique. Son calcul est indépendant du champ $\delta_F$. Elle ne dépend uniquement de la géométrie du relevé (\#prov comment ?) et de la distribution des poids.
La figure~\ref{prov} montre la différence entre \#prov montre la difference du fit d'une réa avec sa DM et avec une autre DM et/ou le stack de 10 avec les 10 DM ou dix fois la meme. Est-ce que les DM eboss-0.0 et eboss-0.2 sont différentes ?
Ainsi, il n'est pas nécessaire de calculer la matrice de distorsion pour les 100 réalisations des mocks.
Dans l'analyse présentée dans la suite de ce chapitre, nous calculons la matrice de distorsion pour l'auto-corrélation et pour la corrélation croisée une seule fois (\#prov ou une fois pour chaque run de quickquasars?). L'ajustement de chaque fonction de corrélation utilise une de ces deux matrices de distorsion.


\section{Les matrices de covariance}
Afin de réalisation l'ajustement de chaque fonction de corrélation, nous avons besoin de calculer les matrices de covariance associées à ces fonctions de corrélation. La covariance de la fonction de corrélation $\xi$ dans le bin $A$ et de $\xi$ dans le bin $B$ est définie comme
\begin{equation}
  C_{AB} = \langle \xi_A \xi_B \rangle - \langle \xi_A \rangle \langle \xi_B \rangle \; .
\end{equation}
De cette matrice de covariance, nous définissons la matrice de corrélation comme
\begin{equation}
  Corr_{AB} = \frac{C_{AB}}{\sqrt{C_{AA} C_{BB}}} \; .
\end{equation}
La matrice de corrélation donne la corrélation, comprise dans $[-1 ; 1]$, d'un bin A avec un bin B.
Afin d'estimer la matrice de covariance, le relevé est divisé en HEALPix pixels, en utilisant $\texttt{nside} = \num{16}$. Cette résolution produit des pixels d'une taille sur le ciel de $\num{3.7} \times \num{3.7} = \SI{13.4}{\square\deg}$, correspondant à $\num{250} \times \num{250} (\si{\perh\Mpc})^2$ à un redshift $z = \num{2.33}$. Ces sous-échantillons sont suffisamment grands pour pouvoir négliger les corrélations entre différents HEALPix pixels et ainsi estimer la matrice de covariance comme la variance d'un sous-échantillon à un autre. La matrice de covariance est donc calculée comme
\begin{equation}
  C_{AB} = \frac{1}{W_A W_B} \sum_s W_A^s W_B^s \left( \xi_A^s \xi_B^s - \xi_A \xi_B \right) \; ,
\end{equation}
où $s$ est un sous-échantillon, et $W_A^s$ les poids du bin $A$ de ce sous-échantillon.
Les principaux éléments de cette matrice sont les éléments diagonaux : la variance dans chaque bin. Les éléments non-diagonaux, les covariances entre deux bins distincts, sont faibles (\#prov donner comme Var\_A est modélisé ? Donner comment on modélise les éléments non diag ?). Leur estimation est bruitée. La matrice de covariance est donc lissée après avoir été estimée.
En ce qui concerne l'auto-corrélation, la matrice de covariance possède $\num{2500} \times \num{2500}$ bins. Pour la corrélation croisée, elle en possède $\num{5000} \times \num{5000}$.



\section{Modélisation des fonctions de corrélation}
Dans cette section, nous présentons les modèles utilisés pour ajuster les fonctions de corrélation \lya{}$\times$\lya{} et \lya{}$\times$QSO. Nous présentons d'abord les modèles utilisés dans l'analyse des données DR16, puis nous donnons les modèles utilisés pour analyser les mocks.

\subsection{Modélisation des données}
Pour l'analyse des données DR16, nous utilisons le modèle décrit dans~\citet{prov}. L'analyse décrite dans cette étude est une analyse BAO : l'auto-corrélation et la corrélation croisée sont modélisées de façon à mesurer au mieux les paramètres BAO $\apar{}$ et $\aperp{}$.
Pour ce faire, le modèle est séparé en deux composantes. La première, $\xi_{smooth}$, correspond à la forme globale de la fonction de corrélation. 
La seconde, $\xi_{peak}$, correspond au pic BAO. C'est cette seconde composante qui dépend des paramètres BAO :
\begin{equation}
  \xi(\rpar{}, \rperp{}, \apar{}, \aperp{}) = \xi_{\mathrm{smooth}}(\rpar{}, \rperp{}) + \xi_{\mathrm{peak}}(\apar{} \rpar{}, \aperp{} \rperp{}) \; .
\end{equation}
Cette séparation est opérée au niveau du spectre de puissance. Le modèle de la fonction de corrélation est ensuite obtenue à l'aide d'une transformation de Fourier.
% Nous donnons dans les lignes qui suivent, comment nous construisons le spectre de puissance utilisé dans la modélisation de la fonction de corrélation des traceurs $i$ et $j$.
% Celui-ci s'exprime comme
% \subsubsection{Le spectre de puissance}
\paragraph{}
Le spectre de puissance utilisé dans la modélisation de la fonction de corrélation des traceurs $i$ et $j$ s'exprime comme
\begin{equation}
  \label{eq:pk_model1}
  P(\vec k) = b_i b_j (1+\beta_i \mu_k^2)(1+\beta_j \mu_k^2) P_{\mathrm{QL}}(\vec k) F_{\mathrm{NL}}(\vec k) G(\vec k) \; .
\end{equation}
% où $b_i$ est le biais du traceur $i$, $\beta_i$ le paramètre RSD du traceur $i$. $P_{QL}$ donne le spectre de puissance \emph{quasi-linéaire}. $F_{NL}$ prend en compte les non linéarités.
Les termes $b_i (1+\beta_i \mu_k^2)$ et $b_j (1+\beta_j \mu_k^2)$ sont les facteurs de Kaiser (équation~\ref{eq:kaiser3}) relatifs aux traceurs $i$ et $j$.
$P_{\mathrm{QL}}$ est le spectre de puissance \emph{quasi-linéaire}. Il est découpé en deux composantes $P_{smooth}$ et $P_{peak}$ comme
\begin{equation}
  P_{\mathrm{QL}}(\vec k, z) = P_{\mathrm{smooth}}(k, z) + \exp(- \frac{k_{\parallel}^2 \Sigma_{\parallel}^2 + k_{\perp}^2 \Sigma_{\perp}^2}{2}) P_{\mathrm{peak}}(k,z) \; .
\end{equation}
$P_{\mathrm{smooth}}$ est le spectre de puissance linéaire, sans les BAO. Il est construit à partir du spectre de puissance linéaire $P_{\mathrm{L}}$ donné par Camb, puis les BAO sont retirées en utilisant la technique \emph{side-band} décrite dans \citet{Kirkby2013}.
Le spectre de puissance $P_{\mathrm{peak}}$ est alors obtenu comme la différence $P_{\mathrm{L}} - P_{\mathrm{smooth}}$ : il contient uniquement les oscillations dues aux BAO présentes dans le spectre de puissance linaire.
Le terme exponentiel devant $P_{\mathrm{peak}}$, paramétré par $\Sigma_{\parallel}$ et $\Sigma_{\perp}$, prend en compte l'élargissement non linéaire du pic BAO \citep{eisenstein_robustness_2007}. Nous utilisons $\Sigma_{\parallel} = \SI{6.42}{\perh\Mpc}$ et $\Sigma_{\perp} = \SI{3.26}{\perh\Mpc}$.
Le terme $F_{\mathrm{NL}}$ prend en compte les non linéarités aux petites échelles. Nous distinguons $F_{\mathrm{NL}}^{\mathrm{auto}}$ et $F_{\mathrm{NL}}^{\mathrm{cross}}$. Pour l'auto-corrélation, les effets non linéaires proviennent de l'élargissement thermique, des vitesses particulières et de la croissance des structures non linéaire.
Comme lors de la modélisation du $P^{1D}$, nous utilisons le modèle décrit dans \citet{Arinyo-i-Prats2015}. Nous avons donc $F_{\mathrm{NL}}^{\mathrm{auto}}(k, \mu) = D(k, \mu)$, où $D$ est défini dans l'équation~\ref{eq:p1d_prats}. Les paramètres utilisés sont une interpolation à $z = \num{2.334}$ de ceux donnés dans la section ``Planck'' de la table 7 de \citet{Arinyo-i-Prats2015}.
Pour la corrélation croisée, l'effet dominant est dû aux vitesses non linéaires des quasars. Cet effet est modélisé par une lorrentzienne :
\begin{equation}
  F_{\mathrm{NL}}^{\mathrm{cross}}(\kpar{}) = \frac{1}{1 + (\kpar{} \sigma_v)^2} \; ,
\end{equation}
où l'inverse de la demi-largeur à mi-hauteur $\sigma_v$ est un paramètre libre. L'effet dû aux erreurs statistiques sur la mesure du redshift des quasars étant confondu avec l'effet des vitesses non linéaires des quasars, il est aussi pris en compte par le terme $  F_{\mathrm{NL}}^{\mathrm{cross}}$.
Enfin, le terme $G(\vec k)$ prend en compte l'effet du binning utilisé lors du calcul de la fonction de corrélation.
Il est défini comme le produit des transformés de Fourier de la fonction porte :
\begin{equation}
  G(\vec k) = \mathrm{sinc}(\frac{\kpar{}R_{\parallel}}{2})\mathrm{sinc}(\frac{\kperp{}R_{\perp}}{2}) \; ,
\end{equation}
avec $R_{\parallel}$ et $R_{\perp}$ la largeur des bins, soit \SI{4}{\perh\Mpc}.



% \subsubsection{Modélisation des HCD}
\paragraph{}
La présence des facteurs de Kaiser dans l'équation~\ref{eq:pk_model1} permet de mesurer le biais et le paramètre RSD de nos traceurs. En ce qui concerne l'auto-corrélation \lya{}$\times$\lya{}, la fonction de corrélation est proportionnelle à $b_{\mathrm{Ly}\alpha}^2(1+\beta_{\mathrm{Ly}\alpha} \mu^2)^2$. Cependant, la présence de HCD dans les données modifie le biais effectif du \lya{}. En effet, l'efficacité de l'algorithme de détection n'étant pas de \SI{100}{\percent}, il subsiste des DLA non identifiés dans les forêts. De plus, les HCD avec $\log n_{HI} < 20.3$ ne sont pas identifiés. Ces deux effets participent à augmenter le biais mesuré du \lya{} significativement. Nous utilisons les paramètres effectifs
\begin{align}
  b_{\mathrm{Ly}\alpha}' &= b_{\mathrm{Ly}\alpha} + b_{\textsc{HCD}} F_{\textsc{HCD}}(\kpar{}) \; , \\
  b_{\mathrm{Ly}\alpha}' \beta_{\mathrm{Ly}\alpha}' &= b_{\mathrm{Ly}\alpha} \beta_{\mathrm{Ly}\alpha} + b_{\textsc{HCD}} \beta_{\textsc{HCD}} F_{\textsc{HCD}}(\kpar{})  \; ,
\end{align}
où $F_{\textsc{HCD}}$ est une fonction qui dépend de la distribution en $z$ et en $\log n_{HI}$ des HCD \citep{font-ribera_effect_2012}. Cette fonction est estimée sur des simulations hydrodynamiques \citep{Rogers2017}. Nous la modélisons comme
\begin{equation}
  F_{\textsc{HCD}}(\kpar{}) = \exp(- L_{\textsc{HCD}} \kpar{}) \; ,
\end{equation}
où $L_{\textsc{HCD}}$ est la taille typique des HCD non masqués. La résolution du spectrographe d'eBOSS rend possible l'identification des DLAs dont la largeur est supérieure à \SI{2}{\nano\meter}, correspondant à une taille d'environ \SI{14}{\perh\Mpc} à redshift effectif de la mesure. De plus, $L_{\textsc{HCD}}$ est très dégénéré avec avec les autres paramètres du modèle, comme le biais des HCD ou les paramètres du \lya{}. Nous fixons sa valeur à \SI{10}{\perh\Mpc} dans l'ajustement du modèle.

Afin de pouvoir ajuster le même modèle sur tous les bins $(\rpar{}, \rperp)$, nous tenons compte de la dépendance en redshit de $\delta_F$. Nous avons $\delta_F(z) \propto G(z) b_{\mathrm{Ly}\alpha}(z)$, avec $G(z) \propto (1+z)^{-1}$. Concernant le biais du \lya{}, nous utilisons la même dépendance que celle choisie lors du calcul des poids (équation~\ref{eq:wieghts2}), c'est à dire $b_{\mathrm{Ly}\alpha} \propto (1+z)^{\gamma_{\mathrm{Ly}\alpha}}$, avec $\gamma_{\mathrm{Ly}\alpha} = 2.9$ \citep{mcdonald_ly_2006}.
En ce qui concerne $\beta_{\mathrm{Ly}\alpha}$, nous considérons lors de l'ajustement du modèle qu'il est indépendant du redshift. Comme montré dans l'analyse présentée dans le chapitre~\ref{}, $\beta_{\mathrm{Ly}\alpha}$ n'est pas indépendant du redshift. Cependant, le redshift moyen dans chaque bin $(\rpar{}, \rperp)$ varie peu. Lors de l'analyse de l'ensemble des données DR16, il varie dans la gamme $\num{2.31} < z < \num{2.39}$. Cette variation correspond à une variation de $\beta_{\mathrm{Ly}\alpha}$ de moins de \SI{5}{\percent}. De plus, elle est d'autant plus faible lorsque l'analyse est faite dans différents bins en redshift.

La fonction de corrélation croisée \lya{}$\times$QSO est sensible au produit $b_{\mathrm{Ly}\alpha}(1+\beta_{\mathrm{Ly}\alpha} \mu^2) b_{\textsc{QSO}}(1+\beta_{\textsc{QSO}} \mu^2)$. L'ajustement seul de cette fonction de corrélation ne permet donc pas de distinguer les paramètres \lya{} des paramètres des QSO. Nous fixons donc $b_{\textsc{QSO}}$ et $\beta_{\textsc{QSO}}$. Concernant le biais, comme pour le \lya{} nous prenant en compte l'évolution avec le redshift. Il est paramétrisé comme
\begin{equation}
  b_{\textsc{QSO}}(z) = \num{3.77} \left( \frac{1 + z}{1+\num{2.334}} \right)^{\num{1.44}} \; . 
\end{equation}
Cette paramétrisation est sensiblement équivalente à celle utilisée dans les mocks (équation~\ref{eq:b_qso}) dans la gamme $\num{2.31} < z < \num{2.39}$. $\beta_{\textsc{QSO}}$ est choisi constant et vaut $\beta_{\textsc{QSO}} = f / b_{\textsc{QSO}}(\num{2.334}) = \num{0.257}$.


\paragraph{}
Une fois les composantes multiplicatives incluses au modèle, nous pouvons transformer le $P(\vec k)$ modèle définit dans l'équation~\ref{eq:pk_model1} en fonction de corrélation $\xi(r, \mu)$.
Cette transformation est faite en utilisant FFTLog \citep{Hamilton1999} : la fonction de corrélation est décomposée en polynômes de Legendre $P_l$ jusqu'à $l_{max} = 6$. Pour chaque $l \in [0 ; 2 ; 4; 6]$, une transformation de Fourier est appliquée au spectre de puissance. Etant donné que la transformation $P(\vec k) \rightarrow \xi(r, \mu)$ est faite à chaque étape de la minimisation lors de l'ajustement du modèle, il est important que cette transformation se fasse très rapidement. Nous utilisons donc l'algorithme FFTLog, qui apporte une rapidité d'exécution pour la précision souhaitée.
Ainsi, en suivant cette procédure, nous obtenons les fonctions de corrélation $\xi_{\mathrm{Ly}\alpha\times\mathrm{Ly}\alpha}$ en choisissant $i = j = \mathrm{Ly}\alpha$, et $\xi_{\mathrm{Ly}\alpha\times\textsc{QSO}}$ en choisissant $i = \mathrm{Ly}\alpha$ et $j = \textsc{QSO}$.
Afin de pouvoir ajuster les fonctions de corrélation calculées avec les données, nous devons prendre en compte dans nos modèles les corrélations parasites. Ces corrélations s'ajoutent au $\xi$ modèle calculé précédemment.
A ce stade, nous distingons le modèle utilisé pour l'auto corrélation et la corrélation croisée.
Le modèle de l'auto corrélation \lya{}$\times$\lya{} est défini comme
\begin{equation}
  \label{eq:cf_model1}
  \xi = \xi_{\mathrm{Ly}\alpha\times\mathrm{Ly}\alpha} + \sum_{m} \xi_{\mathrm{Ly}\alpha\times m} + \sum_{m, n} \xi_{m\times n} + \xi_{ciel}  \; ,
\end{equation}
où $\xi_{\mathrm{Ly}\alpha\times m}$ est la corrélation du \lya{} avec le métal $m$, $\xi_{m_1\times m_2}$ est la corrélation du métal $m_1$ avec le métal $m_2$, et $\xi_{ciel}$ est la corrélation induite par le masquage des lignes de ciel.
Le modèle de la corrélation croisée \lya{}$\times$QSO est défini comme
\begin{equation}
  \label{eq:xcf_model1}
  \xi = \xi_{\mathrm{Ly}\alpha\times \textsc{QSO}} + \sum_{m} \xi_{m \times \textsc{QSO}} + \xi_{prox}  \; ,
\end{equation}
où $ \xi_{m \times \textsc{QSO}}$ est la corrélation du métal $m$ avec les quasars, et $\xi_{prox}$ donne la corrélation induite par l'effet de proximité des quasars.

Afin de modéliser la corrélation des métaux, nous utilisons le modèle défini précédemment, utilisé pour décrire la corrélation $\xi_{\mathrm{Ly}\alpha\times\mathrm{Ly}\alpha}$ et $\xi_{\mathrm{Ly}\alpha\times\textsc{\textsc{QSO}}}$. Lors du calcul du spectre de puissance, nous négligeons l'effet des HCD, ce qui revient à utiliser $b_{\textsc{HCD}} = 0$.
Comme expliqué dans la section~\ref{subsec:contaminants}, toutes les absorptions sont supposées être des absorptions \lya{}. Les absorptions causées par les métaux sont donc reconstruites à un mauvais redshift. Ceci résulte dans un décalage de la fonction de corrélation.
% Pour la corrélation d'un métal $m$ avec le \lya{}, le décalage se fait le long de la ligne de visée : lorsque la séparation physique du métal et du \lya{} est nulle, la séparation reconstruite est $\rperp{} = 0$ et $\rpar{} \sim (1+z)D_H(z)(\lambda_m - \lambda_{\mathrm{Ly}\alpha} ) / \lambda_{\mathrm{Ly}\alpha}$.
De manière générale, pour la corrélation d'un absorbeur $m$ avec un autre absorbeur $n$ ($m \neq n$), le décalage se fait le long de la ligne de visée. Lorsque la séparation physique de ces deux absorbeurs est nulle, la séparation, en supposant que ces deux absorptions sont causées par le \lya{}, est reconstruite à $\rperp{} = 0$ et $\rpar{} \sim (1+z)D_H(z)(\lambda_m - \lambda_{n} ) / \lambda_{\mathrm{Ly}\alpha}$, où $z$ est le redshift moyen des deux absorbeurs.
La fonction de corrélation étant maximale pour $r = 0$, nous attentons donc un excès de corrélation pour ces séparations dans les fonctions de corrélation estimées à partir des données. Les métaux étant beaucoup moins présents dans le milieu intergalatique, les corrélations mettant en jeu deux métaux sont beaucoup moins importantes que les corrélations \lya{}$\times m$ ($m \neq$ \lya). L'effet principal vient donc des corrélations \lya{}$\times m$. 
La table~\ref{tab:metals_in_mocks} donne les séparations associés aux corrélations entre le \lya{} et les métaux ajustés sur les données.
% Les pics associés à ces séparations sont visibles sur la figure~\ref{prov}.
En ce qui concerne les corrélations $m \times m$, le décalage est d'origine différente. Une séparation physique $r=0$ correspond bien à une reconstruction $\rpar{} = \rperp{} = 0$. Cependant, le redshift de la paire est mal estimé. Chaque séparation physique $(\rpar{}, \rperp{})$ est donc reconstruite à $(D_H(z_m) / D_H(z))\rpar{}$ et $(D_M(z_m)/D_M(z))\rperp{}$.
Pour la corrélation $m \times \textsc{QSO}$, le décalage est le même que dans le cas \lya{}$\times m$.

Le décalage de la fonction de corrélation est pris en compte par la \emph{matrice des métaux} $M_{AB}$. Cette matrice permet de relier la fonction de corrélation $\xi_{m\times n}$ de l'absorbeur $m$ avec l'absorbeur $n$ à la fonction de corrélation décalée, utilisée comme modèle dans l'équation~\ref{eq:cf_model1} et~\ref{eq:xcf_model1} :
\begin{equation}
  \xi^{modèle}_{m \times n}(A) = \sum_B M_{AB} \xi_{m\times n}(B) \; ,
\end{equation}
Les bins $A$ correspondent aux séparations calculées en supposant une absorption \lya{}. Les bins $B$ correspondent aux séparations physiques, calculées en utilisant les redshifts $z_m$ et $z_n$ des absorbeurs.
La matrice de distorsion $M_{AB}$ est donnée comme
\begin{equation}
  M_{AB} = \frac{1}{W_A} \sum_B
\end{equation}
\#prov en fait je comprends pas du tout le calcul de la matrice des métaux. Est-ce que c'est nécessaire de donner le détail ?

\begin{table}[]
  \centering
  \caption{Liste des métaux inclus dans le modèle ajusté aux données. La 3\up{e} colonne donne la séparation reconstruire pour une séparation réelle $r=0$. CIV(eff) indique la raie effective du carbon IV : la résolution du spectrographe d'eBOSS étant trop faible pour distinguer le doublet du CIV, nous ajustons la combinaison des deux raies. La séparation liée au CIV est bien supérieure à \SI{200}{\perh\Mpc}, la corrélation \lya{}$\times$CIV n'a donc pas d'effet sur nos mesures. Nous modélisons cependant l'effet lié à l'auto-corrélation CIV$\times$CIV.}
  \label{tab:metals_in_mocks}
  \begin{tabular}{lll}
    \toprule
    Raie  & $\lambda_{m} [\si{\angstrom}]$ & $\rpar{}$ [\si{\perh\Mpc}] \\
    \midrule
    % $\mathrm{Lyman-}\beta$ & \lyb{}  & \num{1025.72} \\
    % $\mathrm{Lyman-}\alpha$ & \lya{} & \num{1215.67} \\
    SiIIa &  \num{1190.4158} & $- 64$ \\
    SiIIb &  \num{1193.2897} & $- 56$  \\
    SiIII &  \num{1206.500}  & $- 21$  \\
    SiIIc &  \num{1260.4221} & $+ 111$ \\
    CIV(eff) & \num{1549.06} & $> 200$ \\
    % Silicium IV & SiIV(1394) & \num{1394.76018} \\
    % Silicium IV & SiIV(1403) & \num{1402.77291} \\
    % Carbon IV & CIV(1548) & \num{1548.2049} \\
    % Carbon IV & CIV(1551) & \num{1550.77845} \\
    % Magnesium II & MgII(2796) & \num{2796.3511} \\
    % Magnesium II & MgII(2804) & \num{2803.5324}\\
    \bottomrule
  \end{tabular}
\end{table}




\bibliography{../source/library}
\end{document}
